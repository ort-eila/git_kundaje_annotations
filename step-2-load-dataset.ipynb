{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1d0b51a6-4042-4faa-adde-f3f4c668fa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2 - load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2605bf13-65a6-4afe-ba74-6cbff5433753",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install transformers datasets faiss-cpu psutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "564eb5d3-7d1f-4a4a-804f-481963598274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from datasets import Features, Sequence, Value, load_dataset\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d9052f82-efcd-41ad-8762-1b3efb012de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e1700ed1-3bcd-43a9-b12c-9f53fbe97dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf output\n",
    "!mkdir output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32766df1-188a-4611-9e4c-4eb7854ed777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "\n",
    "# # Create a logger object\n",
    "# logger = logging.getLogger(__name__)\n",
    "\n",
    "# # Set the logging level to INFO\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "# # Configure the logging settings (optional)\n",
    "# logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# # Log a message\n",
    "# logger.info(\"This is an informational message.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d84de2ad-cfff-494e-957d-5afdc95d2371",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from tempfile import TemporaryDirectory\n",
    "from typing import List, Optional\n",
    "\n",
    "import torch\n",
    "from datasets import Features, Sequence, Value, load_dataset\n",
    "\n",
    "import faiss\n",
    "from transformers import (\n",
    "    DPRContextEncoder,\n",
    "    DPRContextEncoderTokenizerFast,\n",
    "    HfArgumentParser,\n",
    "    RagRetriever,\n",
    "    RagSequenceForGeneration,\n",
    "    RagTokenizer,\n",
    ")\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "torch.set_grad_enabled(False)\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "\n",
    "def split_text(text: str, n=100, character=\" \") -> List[str]:\n",
    "    \"\"\"Split the text every ``n``-th occurrence of ``character``\"\"\"\n",
    "    text = text.split(character)\n",
    "    return [character.join(text[i : i + n]).strip() for i in range(0, len(text), n)]\n",
    "\n",
    "\n",
    "def split_documents(documents: dict) -> dict:\n",
    "    \"\"\"Split documents into passages\"\"\"\n",
    "    titles, texts = [], []\n",
    "    for title, text in zip(documents[\"title\"], documents[\"text\"]):\n",
    "        if text is not None:\n",
    "            for passage in split_text(text):\n",
    "                titles.append(title if title is not None else \"\")\n",
    "                texts.append(passage)\n",
    "    return {\"title\": titles, \"text\": texts}\n",
    "\n",
    "\n",
    "def embed(documents: dict, ctx_encoder: DPRContextEncoder, ctx_tokenizer: DPRContextEncoderTokenizerFast) -> dict:\n",
    "    \"\"\"Compute the DPR embeddings of document passages\"\"\"\n",
    "    input_ids = ctx_tokenizer(\n",
    "        documents[\"title\"], documents[\"text\"], truncation=True, padding=\"longest\", return_tensors=\"pt\"\n",
    "    )[\"input_ids\"]\n",
    "    embeddings = ctx_encoder(input_ids.to(device=device), return_dict=True).pooler_output\n",
    "    return {\"embeddings\": embeddings.detach().cpu().numpy()}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class RagExampleArguments:\n",
    "    csv_path: str = field(\n",
    "        default=str(\"\"),\n",
    "        metadata={\"help\": \"Path to a tab-separated csv file with columns 'title' and 'text'\"},\n",
    "    )\n",
    "    question: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Question that is passed as input to RAG. Default is 'What does Moses' rod turn into ?'.\"},\n",
    "    )\n",
    "    rag_model_name: str = field(\n",
    "        default=\"facebook/rag-sequence-nq\",\n",
    "        metadata={\"help\": \"The RAG model to use. Either 'facebook/rag-sequence-nq' or 'facebook/rag-token-nq'\"},\n",
    "    )\n",
    "    dpr_ctx_encoder_model_name: str = field(\n",
    "        default=\"facebook/dpr-ctx_encoder-multiset-base\",\n",
    "        metadata={\n",
    "            \"help\": \"The DPR context encoder model to use. Either 'facebook/dpr-ctx_encoder-single-nq-base' or 'facebook/dpr-ctx_encoder-multiset-base'\"\n",
    "        },\n",
    "    )\n",
    "    output_dir: Optional[str] = field(\n",
    "        default=None,\n",
    "        metadata={\"help\": \"Path to a directory where the dataset passages and the index will be saved\"},\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ProcessingArguments:\n",
    "    num_proc: Optional[int] = field(\n",
    "        default=None,\n",
    "        metadata={\n",
    "            \"help\": \"The number of processes to use to split the documents into passages. Default is single process.\"\n",
    "        },\n",
    "    )\n",
    "    batch_size: int = field(\n",
    "        default=BATCH_SIZE,\n",
    "        metadata={\n",
    "            \"help\": \"The batch size to use when computing the passages embeddings using the DPR context encoder.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class IndexHnswArguments:\n",
    "    d: int = field(\n",
    "        default=768,\n",
    "        metadata={\"help\": \"The dimension of the embeddings to pass to the HNSW Faiss index.\"},\n",
    "    )\n",
    "    m: int = field(\n",
    "        default=128,\n",
    "        metadata={\n",
    "            \"help\": \"The number of bi-directional links created for every new element during the HNSW index construction.\"\n",
    "        },\n",
    "    )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e694f00-ebbc-45b9-a4e9-bc45f4ec0d47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa2a9196-3073-44fa-a686-50766101a3ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if __name__ == \"__main__\":\n",
    "\n",
    "# logging.basicConfig(level=logging.WARNING)\n",
    "# logger.setLevel(logging.INFO)\n",
    "\n",
    "# In place of parser, just create arguments objects.\n",
    "#parser = HfArgumentParser((RagExampleArguments, ProcessingArguments, IndexHnswArguments))\n",
    "#rag_args, processing_args, index_hnsw_args = parser.parse_args_into_dataclasses()\n",
    "\n",
    "rag_args = RagExampleArguments()\n",
    "processing_args = ProcessingArguments()\n",
    "index_hnsw_args = IndexHnswArguments()\n",
    "\n",
    "rag_args.csv_path = \"./wikipedia_details.csv\"\n",
    "\n",
    "rag_args.output_dir = \"./output\"\n",
    "\n",
    "rag_args.question = \"what is BRCA1\"\n",
    "\n",
    "# Probably don't need this...\n",
    "#with TemporaryDirectory() as tmp_dir:\n",
    "#    rag_args.output_dir = rag_args.output_dir or tmp_dir\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f383b87b-39ed-4516-895b-46b81f3e8fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DPR, which stands for Dense Passage Retrieval, is a method for representing passages of text in a \n",
    "# dense vector space, such that similar passages are close to each other in this space. \n",
    "# DPR is commonly used in information retrieval and question-answering systems to efficiently \n",
    "# retrieve relevant passages given a query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7f82862b-0f19-49bf-8a7c-03411b3023a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_dataset(dataset):\n",
    "    if len(dataset) > 0:\n",
    "        for i in range(min(5, len(dataset))):  # Print the first 5 rows or less if dataset is smaller\n",
    "            print(f\"Title: {dataset['title'][i]}\")\n",
    "            print(f\"Text: {dataset['text'][i]}\")\n",
    "            print()\n",
    "    else:\n",
    "        print(\"The dataset is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5af9d929-fcf3-4b66-9969-6cc78b5c1461",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at facebook/dpr-ctx_encoder-multiset-base were not used when initializing DPRContextEncoder: ['ctx_encoder.bert_model.pooler.dense.bias', 'ctx_encoder.bert_model.pooler.dense.weight']\n",
      "- This IS expected if you are initializing DPRContextEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DPRContextEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
      "The tokenizer class you load from this checkpoint is 'DPRQuestionEncoderTokenizer'. \n",
      "The class this function is called from is 'DPRContextEncoderTokenizerFast'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "after map\n",
      "The dataset is empty.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b95f9825ed3e463b8b63dba3dcd8499a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Saving the dataset (0/1 shards): 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "######################################\n",
    "logger.info(\"Step 1 - Create the dataset\")\n",
    "######################################\n",
    "\n",
    "# The dataset needed for RAG must have three columns:\n",
    "# - title (string): title of the document\n",
    "# - text (string): text of a passage of the document\n",
    "# - embeddings (array of dimension d): DPR representation of the passage\n",
    "\n",
    "# Let's say you have documents in tab-separated csv files with columns \"title\" and \"text\"\n",
    "assert os.path.isfile(rag_args.csv_path), \"Please provide a valid path to a csv file\"\n",
    "\n",
    "# You can load a Dataset object this way\n",
    "dataset = load_dataset(\n",
    "    \"csv\", data_files=[rag_args.csv_path], split=\"train\", delimiter=\"\\t\", column_names=[\"title\", \"text\"]\n",
    ")\n",
    "\n",
    "# print(\"csv dataset load\")\n",
    "# print_dataset(dataset)\n",
    "\n",
    "# More info about loading csv files in the documentation: https://huggingface.co/docs/datasets/loading_datasets.html?highlight=csv#csv-files\n",
    "\n",
    "# Then split the documents into passages of 100 words\n",
    "dataset = dataset.map(split_documents, batched=True, num_proc=processing_args.num_proc)\n",
    "\n",
    "# And compute the embeddings\n",
    "ctx_encoder = DPRContextEncoder.from_pretrained(rag_args.dpr_ctx_encoder_model_name).to(device=device)\n",
    "ctx_tokenizer = DPRContextEncoderTokenizerFast.from_pretrained(rag_args.dpr_ctx_encoder_model_name)\n",
    "new_features = Features(\n",
    "    {\"text\": Value(\"string\"), \"title\": Value(\"string\"), \"embeddings\": Sequence(Value(\"float32\"))}\n",
    ")  # optional, save as float32 instead of float64 to save space\n",
    "dataset = dataset.map(\n",
    "    partial(embed, ctx_encoder=ctx_encoder, ctx_tokenizer=ctx_tokenizer),\n",
    "    batched=True,\n",
    "    batch_size=processing_args.batch_size,\n",
    "    features=new_features,\n",
    ")\n",
    "\n",
    "print(\"after map\")\n",
    "print_dataset(dataset) \n",
    "\n",
    "# And finally save your dataset\n",
    "passages_path = os.path.join(rag_args.output_dir, \"my_knowledge_dataset\")\n",
    "dataset.save_to_disk(passages_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2061531e-8a92-413c-9f03-30b69d2d0296",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Value(dtype='float32', id=None)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Value(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0d5c04f3-05c8-4324-8303-a4f9bd7229af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequence(feature=\"A BRCA mutation is a mutation in either of the BRCA1 and BRCA2 genes, which are tumour suppressor genes. Hundreds of different types of mutations in these genes have been identified, some of which have been determined to be harmful, while others have no proven impact. Harmful mutations in these genes may produce a hereditary breast–ovarian cancer syndrome in affected persons. Only 5–10% of breast cancer cases in women are attributed to BRCA1 and BRCA2 mutations (with BRCA1 mutations being slightly more common than BRCA2 mutations), but the impact on women with the gene mutation is more profound.[2] Women with harmful mutations in either BRCA1 or BRCA2 have a risk of breast cancer that is about five times the normal risk, and a risk of ovarian cancer that is about ten to thirty times normal.[3] The risk of breast and ovarian cancer is higher for women with a high-risk BRCA1 mutation than with a BRCA2 mutation. Having a high-risk mutation does not guarantee that the woman will develop any type of cancer, or imply that any cancer that appears was actually caused by the mutation, rather than some other factor.High-risk mutations, which disable an important error-free DNA repair process (homology directed repair), significantly increase the person's risk of developing breast cancer, ovarian cancer and certain other cancers. Why BRCA1 and BRCA2 mutations lead preferentially to cancers of the breast and ovary is not known, but lack of BRCA1 function seems to lead to non-functional X-chromosome inactivation. Not all mutations are high-risk; some appear to be harmless variations.  The cancer risk associated with any given mutation varies significantly and depends on the exact type and location of the mutation and possibly other individual factors.Mutations can be inherited from either parent and may be passed on to both sons and daughters.  Each child of a genetic carrier, regardless of sex, has a 50% chance of inheriting the mutated gene from the parent who carries the mutation. As a result, half of the people with BRCA gene mutations are male, who would then pass the mutation on to 50% of their offspring, male or female.  The risk of BRCA-related breast cancers for men with the mutation is higher than for other men, but still low.[4] However, BRCA mutations can increase the risk of other cancers, such as colon cancer, pancreatic cancer, and prostate cancer.Methods to diagnose the likelihood of a patient with mutations in BRCA1 and BRCA2 getting cancer were covered by patents \", length=-1, id=None)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Sequence(\"A BRCA mutation is a mutation in either of the BRCA1 and BRCA2 genes, which are tumour suppressor genes. Hundreds of different types of mutations in these genes have been identified, some of which have been determined to be harmful, while others have no proven impact. Harmful mutations in these genes may produce a hereditary breast–ovarian cancer syndrome in affected persons. Only 5–10% of breast cancer cases in women are attributed to BRCA1 and BRCA2 mutations (with BRCA1 mutations being slightly more common than BRCA2 mutations), but the impact on women with the gene mutation is more profound.[2] Women with harmful mutations in either BRCA1 or BRCA2 have a risk of breast cancer that is about five times the normal risk, and a risk of ovarian cancer that is about ten to thirty times normal.[3] The risk of breast and ovarian cancer is higher for women with a high-risk BRCA1 mutation than with a BRCA2 mutation. Having a high-risk mutation does not guarantee that the woman will develop any type of cancer, or imply that any cancer that appears was actually caused by the mutation, rather than some other factor.High-risk mutations, which disable an important error-free DNA repair process (homology directed repair), significantly increase the person's risk of developing breast cancer, ovarian cancer and certain other cancers. Why BRCA1 and BRCA2 mutations lead preferentially to cancers of the breast and ovary is not known, but lack of BRCA1 function seems to lead to non-functional X-chromosome inactivation. Not all mutations are high-risk; some appear to be harmless variations.  The cancer risk associated with any given mutation varies significantly and depends on the exact type and location of the mutation and possibly other individual factors.Mutations can be inherited from either parent and may be passed on to both sons and daughters.  Each child of a genetic carrier, regardless of sex, has a 50% chance of inheriting the mutated gene from the parent who carries the mutation. As a result, half of the people with BRCA gene mutations are male, who would then pass the mutation on to 50% of their offspring, male or female.  The risk of BRCA-related breast cancers for men with the mutation is higher than for other men, but still low.[4] However, BRCA mutations can increase the risk of other cancers, such as colon cancer, pancreatic cancer, and prostate cancer.Methods to diagnose the likelihood of a patient with mutations in BRCA1 and BRCA2 getting cancer were covered by patents \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a31ed77-a96a-44aa-8d2d-612d1f86f7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sequence(Value(\"float32\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96051c6d-7141-476e-9115-d24abbceea86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset is empty.\n"
     ]
    }
   ],
   "source": [
    "#debug\n",
    "from datasets import load_from_disk\n",
    "dataset = load_from_disk(passages_path)  # to reload the dataset\n",
    "print_dataset(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c9f8d3d-6b58-4794-8162-2fdeb727232d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Columns ['embeddings'] not in the dataset. Current columns in the dataset: ['title', 'text']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 7\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m######################################\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Let's use the Faiss implementation of HNSW for fast approximate nearest neighbor search\u001b[39;00m\n\u001b[1;32m      6\u001b[0m index \u001b[38;5;241m=\u001b[39m faiss\u001b[38;5;241m.\u001b[39mIndexHNSWFlat(index_hnsw_args\u001b[38;5;241m.\u001b[39md, index_hnsw_args\u001b[38;5;241m.\u001b[39mm, faiss\u001b[38;5;241m.\u001b[39mMETRIC_INNER_PRODUCT)\n\u001b[0;32m----> 7\u001b[0m dataset\u001b[38;5;241m.\u001b[39madd_faiss_index(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124membeddings\u001b[39m\u001b[38;5;124m\"\u001b[39m, custom_index\u001b[38;5;241m=\u001b[39mindex)\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# And save the index\u001b[39;00m\n\u001b[1;32m     10\u001b[0m index_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(rag_example_args\u001b[38;5;241m.\u001b[39moutput_dir, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmy_knowledge_dataset_hnsw_index.faiss\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:5692\u001b[0m, in \u001b[0;36mDataset.add_faiss_index\u001b[0;34m(self, column, index_name, device, string_factory, metric_type, custom_index, batch_size, train_size, faiss_verbose, dtype)\u001b[0m\n\u001b[1;32m   5626\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madd_faiss_index\u001b[39m(\n\u001b[1;32m   5627\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5628\u001b[0m     column: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5637\u001b[0m     dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mfloat32,\n\u001b[1;32m   5638\u001b[0m ):\n\u001b[1;32m   5639\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Add a dense index using Faiss for fast retrieval.\u001b[39;00m\n\u001b[1;32m   5640\u001b[0m \u001b[38;5;124;03m    By default the index is done over the vectors of the specified column.\u001b[39;00m\n\u001b[1;32m   5641\u001b[0m \u001b[38;5;124;03m    You can specify `device` if you want to run it on GPU (`device` must be the GPU index).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5690\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   5691\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5692\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mformatted_as(\u001b[38;5;28mtype\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnumpy\u001b[39m\u001b[38;5;124m\"\u001b[39m, columns\u001b[38;5;241m=\u001b[39m[column], dtype\u001b[38;5;241m=\u001b[39mdtype):\n\u001b[1;32m   5693\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39madd_faiss_index(\n\u001b[1;32m   5694\u001b[0m             column\u001b[38;5;241m=\u001b[39mcolumn,\n\u001b[1;32m   5695\u001b[0m             index_name\u001b[38;5;241m=\u001b[39mindex_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5702\u001b[0m             faiss_verbose\u001b[38;5;241m=\u001b[39mfaiss_verbose,\n\u001b[1;32m   5703\u001b[0m         )\n\u001b[1;32m   5704\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[1;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:2469\u001b[0m, in \u001b[0;36mDataset.formatted_as\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2467\u001b[0m old_output_all_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output_all_columns\n\u001b[1;32m   2468\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2469\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_format(\u001b[38;5;28mtype\u001b[39m, columns, output_all_columns, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m   2470\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   2471\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/fingerprint.py:511\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    507\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 511\u001b[0m out \u001b[38;5;241m=\u001b[39m func(dataset, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:  \u001b[38;5;66;03m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.11/site-packages/datasets/arrow_dataset.py:2533\u001b[0m, in \u001b[0;36mDataset.set_format\u001b[0;34m(self, type, columns, output_all_columns, **format_kwargs)\u001b[0m\n\u001b[1;32m   2531\u001b[0m     columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(columns)\n\u001b[1;32m   2532\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(col \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names \u001b[38;5;28;01mfor\u001b[39;00m col \u001b[38;5;129;01min\u001b[39;00m columns):\n\u001b[0;32m-> 2533\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m\u001b[38;5;250m \u001b[39mcol:\u001b[38;5;250m \u001b[39mcol\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names,\u001b[38;5;250m \u001b[39mcolumns))\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39mcolumn_names\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2535\u001b[0m     )\n\u001b[1;32m   2536\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m columns \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   2537\u001b[0m     columns \u001b[38;5;241m=\u001b[39m columns\u001b[38;5;241m.\u001b[39mcopy()  \u001b[38;5;66;03m# Ensures modifications made to the list after this call don't cause bugs\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: Columns ['embeddings'] not in the dataset. Current columns in the dataset: ['title', 'text']"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "logger.info(\"Step 2 - Index the dataset\")\n",
    "######################################\n",
    "\n",
    "# Let's use the Faiss implementation of HNSW for fast approximate nearest neighbor search\n",
    "index = faiss.IndexHNSWFlat(index_hnsw_args.d, index_hnsw_args.m, faiss.METRIC_INNER_PRODUCT)\n",
    "dataset.add_faiss_index(\"embeddings\", custom_index=index)\n",
    "\n",
    "# And save the index\n",
    "index_path = os.path.join(rag_example_args.output_dir, \"my_knowledge_dataset_hnsw_index.faiss\")\n",
    "dataset.get_index(\"embeddings\").save(index_path)\n",
    "# dataset.load_faiss_index(\"embeddings\", index_path)  # to reload the index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3e304fc-c311-4d28-b0da-a764f6bec26d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
